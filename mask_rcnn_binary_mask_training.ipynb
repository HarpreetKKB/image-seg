{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Mask Generation using Mask R-CNN\n",
    "\n",
    "This notebook demonstrates how to train a Mask R-CNN model to generate binary masks for images. We'll use a dataset with 50 images and 50 corresponding binary masks.\n",
    "\n",
    "The notebook includes:\n",
    "1. Data preparation and loading\n",
    "2. Model definition and customization\n",
    "3. Training the model on our dataset\n",
    "4. Validation and performance metrics\n",
    "5. Testing on new images and visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Dataset and DataLoader Classes\n",
    "\n",
    "We'll create a custom dataset class to load our images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryMaskDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (string): Directory with all the images\n",
    "            mask_dir (string): Directory with all the masks\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all file names\n",
    "        self.img_names = sorted([f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))])\n",
    "        self.mask_names = sorted([f for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))])\n",
    "        \n",
    "        # Verify that we have the same number of images and masks\n",
    "        assert len(self.img_names) == len(self.mask_names), \"Number of images and masks should be the same\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Load mask\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_names[idx])\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Convert to grayscale\n",
    "        \n",
    "        # Convert mask to binary (0 and 1)\n",
    "        mask = np.array(mask)\n",
    "        mask = (mask > 0).astype(np.uint8)  # Threshold to create binary mask\n",
    "        \n",
    "        # Get bounding boxes from mask\n",
    "        num_objs = 1  # We're treating the entire mask as one object\n",
    "        \n",
    "        # Find contours in the mask\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Initialize boxes and labels\n",
    "        boxes = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # Only include boxes with sufficient area\n",
    "            if w > 10 and h > 10:  # Minimum size threshold\n",
    "                boxes.append([x, y, x+w, y+h])\n",
    "        \n",
    "        # If no valid boxes were found, create a dummy box for the entire mask\n",
    "        if len(boxes) == 0:\n",
    "            non_zero = np.nonzero(mask)\n",
    "            if len(non_zero[0]) > 0 and len(non_zero[1]) > 0:\n",
    "                y_min, y_max = np.min(non_zero[0]), np.max(non_zero[0])\n",
    "                x_min, x_max = np.min(non_zero[1]), np.max(non_zero[1])\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "            else:\n",
    "                # If mask is empty, create a small dummy box\n",
    "                boxes.append([0, 0, 10, 10])\n",
    "        \n",
    "        # Convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.ones((len(boxes),), dtype=torch.int64)  # All objects are of the same class\n",
    "        masks = torch.as_tensor(mask, dtype=torch.uint8)\n",
    "        \n",
    "        # If we have multiple objects, create a mask for each object\n",
    "        if len(boxes) > 1:\n",
    "            # Create individual masks for each object\n",
    "            obj_masks = torch.zeros((len(boxes), mask.shape[0], mask.shape[1]), dtype=torch.uint8)\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = box.int().tolist()\n",
    "                # Create a mask for this box\n",
    "                temp_mask = np.zeros_like(mask)\n",
    "                temp_mask[y1:y2, x1:x2] = mask[y1:y2, x1:x2]\n",
    "                obj_masks[i] = torch.as_tensor(temp_mask, dtype=torch.uint8)\n",
    "            masks = obj_masks\n",
    "        else:\n",
    "            # Just one object, expand dimensions to make it [1, H, W]\n",
    "            masks = masks.unsqueeze(0)\n",
    "        \n",
    "        # Create target dictionary\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your image and mask directories\n",
    "img_dir = \"path_to_images_folder\"  # Replace with your actual path\n",
    "mask_dir = \"path_to_masks_folder\"  # Replace with your actual path\n",
    "\n",
    "# Create the dataset\n",
    "full_dataset = BinaryMaskDataset(img_dir=img_dir, mask_dir=mask_dir, transform=data_transform)\n",
    "\n",
    "# Split the dataset into train, validation and test sets\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.7 * dataset_size)  # 70% for training\n",
    "val_size = int(0.15 * dataset_size)   # 15% for validation\n",
    "test_size = dataset_size - train_size - val_size  # Remaining for testing\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size, test_size], \n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Dataset size: {dataset_size}\")\n",
    "print(f\"Training set size: {train_size}\")\n",
    "print(f\"Validation set size: {val_size}\")\n",
    "print(f\"Test set size: {test_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define and Initialize the Mask R-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    # Load pre-trained Mask R-CNN model\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    # Get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    \n",
    "    # Replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "# 2 classes: background and foreground\n",
    "model = get_model_instance_segmentation(num_classes=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create the Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with tqdm(data_loader, desc=\"Training\") as pbar:\n",
    "        for images, targets in pbar:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            # Forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            epoch_loss += losses.item()\n",
    "            pbar.set_postfix({\"loss\": losses.item()})\n",
    "    \n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create the Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    iou_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(data_loader, desc=\"Validation\") as pbar:\n",
    "            for images, targets in pbar:\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                # Get model predictions\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Calculate IoU for each image\n",
    "                for i, (output, target) in enumerate(zip(outputs, targets)):\n",
    "                    # Get the predicted mask with highest score\n",
    "                    if len(output['scores']) > 0:\n",
    "                        # Get the predicted mask with highest score\n",
    "                        pred_mask = output['masks'][0, 0].cpu().numpy() > 0.5\n",
    "                        \n",
    "                        # Get the ground truth mask\n",
    "                        gt_mask = target['masks'][0].cpu().numpy()\n",
    "                        \n",
    "                        # Calculate IoU\n",
    "                        intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "                        union = np.logical_or(pred_mask, gt_mask).sum()\n",
    "                        iou = intersection / union if union > 0 else 0\n",
    "                        iou_scores.append(iou)\n",
    "    \n",
    "    # Calculate mean IoU\n",
    "    mean_iou = np.mean(iou_scores) if len(iou_scores) > 0 else 0\n",
    "    \n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Initialize optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Training history\n",
    "history = {'train_loss': [], 'val_iou': []}\n",
    "\n",
    "# Best model tracking\n",
    "best_iou = 0\n",
    "best_model_weights = None\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss = train_one_epoch(model, optimizer, train_dataloader, device)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_iou = validate(model, val_dataloader, device)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    \n",
    "    # Update learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Validation IoU: {val_iou:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_iou > best_iou:\n",
    "        best_iou = val_iou\n",
    "        best_model_weights = model.state_dict().copy()\n",
    "        print(f\"New best model with IoU: {best_iou:.4f}\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_weights)\n",
    "print(f\"\\nTraining completed. Best validation IoU: {best_iou:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mask_rcnn_binary_mask_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot validation IoU\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_iou'])\n",
    "plt.title('Validation IoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean IoU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test on Validation Set and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize model predictions\n",
    "def visualize_prediction(model, image, target, device):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Send image to device\n",
    "    image = image.to(device)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = model([image])[0]\n",
    "    \n",
    "    # Convert image back to numpy for visualization\n",
    "    # Denormalize image\n",
    "    image = image.cpu().numpy().transpose(1, 2, 0)\n",
    "    image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    # Get ground truth mask\n",
    "    gt_mask = target['masks'][0].cpu().numpy()\n",
    "    \n",
    "    # Get predicted mask\n",
    "    if len(prediction['masks']) > 0 and prediction['scores'][0] > 0.5:\n",
    "        pred_mask = prediction['masks'][0, 0].cpu().numpy() > 0.5\n",
    "    else:\n",
    "        pred_mask = np.zeros_like(gt_mask)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Ground truth mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(gt_mask, cmap='gray')\n",
    "    plt.title('Ground Truth Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Predicted mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred_mask, cmap='gray')\n",
    "    plt.title(f'Predicted Mask (IoU: {iou:.3f})')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on several validation images\n",
    "num_test_images = min(5, len(test_dataset))  # Test on up to 5 images\n",
    "test_iou_scores = []\n",
    "\n",
    "for i in range(num_test_images):\n",
    "    image, target = test_dataset[i]\n",
    "    iou = visualize_prediction(model, image, target, device)\n",
    "    test_iou_scores.append(iou)\n",
    "    print(f\"Test image {i+1}, IoU: {iou:.4f}\")\n",
    "\n",
    "mean_test_iou = np.mean(test_iou_scores)\n",
    "print(f\"\\nMean test IoU: {mean_test_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Additional Function: Use Your Provided Mask R-CNN Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_maskrcnn(image):\n",
    "    \"\"\"Apply pre-trained Mask R-CNN model\"\"\"\n",
    "    # Load a pre-trained Mask R-CNN model\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.to('cuda')\n",
    "\n",
    "    # Prepare image for the model\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    input_tensor = transform(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_batch)\n",
    "\n",
    "    # Initialize an empty mask with the same dimensions as the image\n",
    "    mask = np.zeros((image.height, image.width), dtype=np.uint8)\n",
    "\n",
    "    # Process predictions\n",
    "    for i, score in enumerate(prediction[0]['scores']):\n",
    "        if score > 0.5:  # confidence threshold\n",
    "            mask_tensor = prediction[0]['masks'][i, 0].cpu().numpy()\n",
    "            mask_binary = (mask_tensor > 0.5).astype(np.uint8)\n",
    "            mask = np.logical_or(mask, mask_binary).astype(np.uint8)\n",
    "\n",
    "    # Convert to binary mask\n",
    "    binary_mask = mask * 255\n",
    "\n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pre-trained model with our fine-tuned model\n",
    "def compare_models(image_path, device):\n",
    "    # Load image\n",
    "    pil_image = Image.open(image_path).convert(\"RGB\")\n",
    "    cv_image = cv2.imread(image_path)\n",
    "    cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get mask from pre-trained model\n",
    "    pretrained_mask = apply_maskrcnn(pil_image)\n",
    "    \n",
    "    # Get mask from our fine-tuned model\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    input_tensor = transform(pil_image).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model([input_tensor])[0]\n",
    "    \n",
    "    if len(prediction['masks']) > 0 and prediction['scores'][0] > 0.5:\n",
    "        finetuned_mask = (prediction['masks'][0, 0].cpu().numpy() > 0.5) * 255\n",
    "    else:\n",
    "        finetuned_mask = np.zeros((pil_image.height, pil_image.width), dtype=np.uint8)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv_image_rgb)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(pretrained_mask, cmap='gray')\n",
    "    plt.title('Pre-trained Mask R-CNN')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(finetuned_mask, cmap='gray')\n",
    "    plt.title('Fine-tuned Mask R-CNN')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test comparison on a sample image (replace with an actual test image path)\n",
    "# sample_image_path = \"path_to_test_image.jpg\"  # Replace with your test image path\n",
    "# compare_models(sample_image_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we have:\n",
    "1. Created a custom dataset for binary mask segmentation\n",
    "2. Loaded and prepared the data with proper transformations\n",
    "3. Initialized a Mask R-CNN model with a pre-trained backbone\n",
    "4. Fine-tuned the model on our dataset\n",
    "5. Evaluated the model using IoU metric\n",
    "6. Visualized the results and compared with a pre-trained model\n",
    "\n",
    "Potential next steps:\n",
    "- Experiment with different backbones (ResNet-101, etc.)\n",
    "- Try different data augmentation techniques\n",
    "- Tune hyperparameters (learning rate, batch size, etc.)\n",
    "- Apply post-processing to improve mask quality\n",
    "- Implement ensemble methods for better predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}